{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16715,"status":"ok","timestamp":1667409428147,"user":{"displayName":"Guru Aakash G","userId":"07505285016390291133"},"user_tz":-330},"id":"TMT5oTahtpqC","outputId":"bad3cbf6-1835-4dd8-de39-a1163c283101"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting deap\n","  Downloading deap-1.3.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB)\n","\u001b[K     |████████████████████████████████| 139 kB 14.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deap) (1.21.6)\n","Installing collected packages: deap\n","Successfully installed deap-1.3.3\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorboardX\n","  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 7.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.6)\n","Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (1.15.0)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-2.5.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting thop\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from thop) (1.12.1+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->thop) (4.1.1)\n","Installing collected packages: thop\n","Successfully installed thop-0.1.1.post2209072238\n"]}],"source":["!pip install deap\n","!pip install tensorboardX\n","!pip install thop"]},{"cell_type":"markdown","metadata":{"id":"iE-WaGwduIAZ"},"source":["# Import modules"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22890,"status":"ok","timestamp":1667409451031,"user":{"displayName":"Guru Aakash G","userId":"07505285016390291133"},"user_tz":-330},"id":"eXI4RB9M3b9f","outputId":"322e575f-9b8c-48c8-f3a0-87c58fb94c0e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive/', force_remount=True)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1667409451032,"user":{"displayName":"Guru Aakash G","userId":"07505285016390291133"},"user_tz":-330},"id":"H8w8PJjT3dSo"},"outputs":[],"source":["import sys    \n","path_to_module = '/content/gdrive/MyDrive/IT402'\n","sys.path.append(path_to_module)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"herNzKP1ORS2","executionInfo":{"status":"ok","timestamp":1667409451032,"user_tz":-330,"elapsed":5,"user":{"displayName":"Guru Aakash G","userId":"07505285016390291133"}}},"outputs":[],"source":["output_path = \"/content/gdrive/MyDrive/IT402/output/\"\n","data_path = \"/content/gdrive/MyDrive/IT402/\""]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":10149,"status":"ok","timestamp":1667409461177,"user":{"displayName":"Guru Aakash G","userId":"07505285016390291133"},"user_tz":-330},"id":"HEuXO8nD5VFg"},"outputs":[],"source":["from scipy.special import comb\n","from deap import base, creator, tools\n","from tensorboardX import SummaryWriter\n","from thop import profile\n","from os import path\n","from PIL import Image, ImageFilter\n","from tqdm import tqdm\n","from torch import nn\n","from torch.optim.optimizer import Optimizer\n","from torch.nn.utils.clip_grad import clip_grad_norm_\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset\n","from torch.utils.data import Subset\n","from torchvision.transforms import functional as TF\n","from torchvision.datasets.utils import list_files\n","\n","from metrics.average_meter import AverageMeter\n","from metrics.calculate_metrics import calculate_metrics\n","from genetic_model import UnetBlock, check_active, count_param, Net\n","\n","import torch.multiprocessing\n","import os\n","import sys\n","import time\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import random\n","import pickle\n","import numpy as np\n","import torch.multiprocessing\n","import matplotlib.pyplot as plt\n","import multiprocessing.pool\n","import itertools as it\n","import math\n","import shutil\n","import multiprocessing as mp"]},{"cell_type":"markdown","metadata":{"id":"5JgYrESF2Pa6"},"source":["# Dataset"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":442,"status":"ok","timestamp":1667409461616,"user":{"displayName":"Guru Aakash G","userId":"07505285016390291133"},"user_tz":-330},"id":"dOZ9UIUK2VW5"},"outputs":[],"source":["class DRIVE_dataset(Dataset):\n","\n","    def __init__(self, data_root, train=True, transforms=None):\n","        super(DRIVE_dataset, self).__init__()\n","        self.data_root = data_root\n","        self.transforms = transforms\n","        self.num_return = 2\n","        self.dataset = DRIVEPILDataset(self.data_root)\n","        self.train = train\n","\n","    def __getitem__(self, index):\n","        image, annot = self.dataset[index]\n","\n","        if self.transforms is None:\n","            image, annot = self._default_trans(image, annot, self.train)\n","        else:\n","            image, annot = self.transforms(image, annot)\n","\n","        return image, annot\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    @staticmethod\n","    def _default_trans(image, annot, train):\n","\n","        annot = TF.to_grayscale(annot, num_output_channels=1)\n","        if train:\n","            if random.random() < 0.5:\n","                image = TF.hflip(image)\n","                annot = TF.hflip(annot)\n","            #\n","            if random.random() < 0.5:\n","                image = TF.vflip(image)\n","                annot = TF.vflip(annot)\n","            if random.random() < 0.6:\n","                angle = random.random() * 360\n","                image = TF.rotate(img=image, angle=angle)\n","                annot = TF.rotate(img=annot, angle=angle)\n","\n","        image = TF.to_tensor(image)\n","        image = TF.normalize(image, mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n","\n","        annot = TF.to_tensor(annot)\n","        annot[annot > 0.5] = 1\n","        annot[annot < 0.5] = 0\n","        return image, annot"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1667409461616,"user":{"displayName":"Guru Aakash G","userId":"07505285016390291133"},"user_tz":-330},"id":"3w7tPww82XN-"},"outputs":[],"source":["class DRIVEPILDataset(Dataset):\n","    def __init__(self, data_root):\n","        self.data_root = path.expanduser(data_root)\n","        self._image_dir = path.join(self.data_root, 'images')\n","        self._annot_dir = path.join(self.data_root, 'labels')\n","\n","        self._image_paths = sorted(list_files(self._image_dir, suffix=('.tif', '.TIF'), prefix=True))\n","        self._annot_paths = sorted(list_files(self._annot_dir, suffix=('.gif', '.GIF'), prefix=True))\n","\n","    def __getitem__(self, index):\n","        image = Image.open(self._image_paths[index], mode='r').convert('RGB')\n","        annot = Image.open(self._annot_paths[index], mode='r').convert('1')\n","        return image, annot\n","\n","    def __len__(self):\n","        return len(self._image_paths)\n","\n","def get_datasets(dataset_name, data_root, train, transforms=None):\n","    if dataset_name == 'DRIVE':\n","        dataset = DRIVE_dataset(data_root=data_root, train=train, transforms=transforms)\n","        num_return = dataset.num_return\n","    else:\n","        raise NotImplementedError\n","\n","    return dataset, num_return"]},{"cell_type":"markdown","metadata":{"id":"DQcraGcduWDn"},"source":["# Model"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13493,"status":"ok","timestamp":1667409475107,"user":{"displayName":"Guru Aakash G","userId":"07505285016390291133"},"user_tz":-330},"id":"TwGIHXXAuS3Z","outputId":"9081a4af-84b2-4857-f621-0fbdd3bf4d3b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total parameters:  81900\n"]}],"source":["active, pre_index, out_index = check_active(node_num=5, connect_gene=list(np.random.randint(0, 2, size=[10])))\n","model = UnetBlock(base_ch=36, active=active, pre_index=pre_index, out_index=out_index, node_func_type='conv_in_mish_3').cuda(0)\n","# model = get_func('conv_in_mish_3', channel=16)\n","x = torch.rand(1, 36, 64, 64).cuda(0)\n","y = model(x)\n","param = count_param(model)\n","print('Total parameters: ',param)"]},{"cell_type":"markdown","metadata":{"id":"9bd76Rkh3u_j"},"source":["# Training"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":461,"status":"ok","timestamp":1667409755600,"user":{"displayName":"Guru Aakash G","userId":"07505285016390291133"},"user_tz":-330},"id":"IsoF-HKQwsyr"},"outputs":[],"source":["class NoDaemonProcess(mp.Process):\n","\n","    def _get_daemon(self):\n","        return False\n","\n","    def _set_daemon(self, value):\n","        pass\n","\n","    daemon = property(_get_daemon, _set_daemon)\n","\n","\n","class NoDaemonProcessPool(multiprocessing.pool.Pool):\n","    Process = NoDaemonProcess"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1667409782792,"user":{"displayName":"Guru Aakash G","userId":"07505285016390291133"},"user_tz":-330},"id":"kYovGvLvwdCL"},"outputs":[],"source":["def func_try(population, ind_num, device, model_settings):\n","    i = 0\n","    seed = 12\n","    \n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    #torch.cuda.set_device(device=device)\n","    \n","    while True:\n","        i += 1\n","        mem_max_cached = torch.cuda.max_memory_cached(device=device) / 1000 ** 3\n","        mem_used_cached = torch.cuda.memory_cached(device=device) / 1000 ** 3\n","        torch.cuda.reset_max_memory_cached(device=device)\n","        torch.cuda.reset_max_memory_allocated(device=device)\n","        if i > 5:\n","            break\n","        if mem_max_cached > 9 and mem_used_cached > 1:\n","            curr_device = torch.cuda.current_device()\n","            torch.cuda.empty_cache()\n","            time.sleep(3)\n","        else:\n","            break\n","    temp = population[ind_num][0:150]\n","    population[ind_num] = tools.mutFlipBit(population[ind_num], indpb=0.3)[0]\n","    population[ind_num][0:150] = temp\n","    model = Net(gene=population[ind_num][:], model_settings=model_settings)\n","    print('Have changed the channel number!')\n","\n","    return model, device\n","\n","\n","def help_func(optimizer_name, learning_rate, l2_weight_decay, gen_num, ind_num, model, batch_size, epochs, device,\n","              train_set_name, valid_set_name,\n","              train_set_root, valid_set_root, exp_name,\n","              population, model_settings):\n","    metrics, flag = train_one_model(optimizer_name, learning_rate, l2_weight_decay, gen_num, ind_num, model, batch_size,\n","                                    epochs, device, train_set_name,\n","                                    valid_set_name,\n","                                    train_set_root, valid_set_root, exp_name)\n","    if flag == False:\n","        while True:\n","            model, device = func_try(population, ind_num, device, model_settings)\n","            metrics, flag = train_one_model(optimizer_name, learning_rate, l2_weight_decay, gen_num, ind_num, model,\n","                                            batch_size, epochs, device,\n","                                            train_set_name, valid_set_name,\n","                                            train_set_root, valid_set_root, exp_name)\n","            if flag == True:\n","                break\n","\n","    return metrics\n","\n","\n","def util_function(i):\n","    return help_func(i[0], i[1], i[2], i[3], i[4], i[5], i[6], i[7], i[8], i[9], i[10], i[11], i[12], i[13], i[14], i[15])"]},{"cell_type":"markdown","metadata":{"id":"G6TBG5rw1Yu9"},"source":["Optimizer"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1667409757138,"user":{"displayName":"Guru Aakash G","userId":"07505285016390291133"},"user_tz":-330},"id":"F1wvCFwK1P8j"},"outputs":[],"source":["class Lookahead(Optimizer):\n","    def __init__(self, base_optimizer,alpha=0.5, k=6):\n","        if not 0.0 <= alpha <= 1.0:\n","            raise ValueError(f'Invalid slow update rate: {alpha}')\n","        if not 1 <= k:\n","            raise ValueError(f'Invalid lookahead steps: {k}')\n","        self.optimizer = base_optimizer\n","        self.param_groups = self.optimizer.param_groups\n","        self.alpha = alpha\n","        self.k = k\n","        for group in self.param_groups:\n","            group[\"step_counter\"] = 0\n","        self.slow_weights = [[p.clone().detach() for p in group['params']]\n","                                for group in self.param_groups]\n","\n","        for w in it.chain(*self.slow_weights):\n","            w.requires_grad = False\n","\n","    def step(self, closure=None):\n","        loss = None\n","        if closure is not None:\n","            loss = closure()\n","        loss = self.optimizer.step()\n","        for group,slow_weights in zip(self.param_groups,self.slow_weights):\n","            group['step_counter'] += 1\n","            if group['step_counter'] % self.k != 0:\n","                continue\n","            for p,q in zip(group['params'],slow_weights):\n","                if p.grad is None:\n","                    continue\n","                q.data.add_(self.alpha,p.data - q.data)\n","                p.data.copy_(q.data)\n","        return loss\n","\n","def get_optimizer(optimizer_name, params, learning_rate, l2_weight_decay):\n","    if optimizer_name == 'SGD':\n","        from torch.optim import SGD\n","        optimizer = SGD(params=params, lr=learning_rate, weight_decay=l2_weight_decay)\n","\n","    elif optimizer_name == 'Adam':\n","        from torch.optim import Adam\n","        optimizer = Adam(params=params, lr=learning_rate, weight_decay=l2_weight_decay)\n","\n","    elif optimizer_name == 'RMS':\n","        from torch.optim.rmsprop import RMSprop\n","        optimizer = RMSprop(params=params, lr=learning_rate, weight_decay=l2_weight_decay)\n","\n","    elif optimizer_name == 'Lookahead(Adam)':\n","        from torch.optim import Adam\n","        base_optimizer = Adam(params=params, lr=learning_rate, weight_decay=l2_weight_decay)\n","        optimizer = Lookahead(base_optimizer=base_optimizer)\n","\n","    else:\n","        raise NotImplementedError\n","\n","    return optimizer"]},{"cell_type":"markdown","metadata":{"id":"dKkN-q0-1lhC"},"source":["Loss function"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1667409757138,"user":{"displayName":"Guru Aakash G","userId":"07505285016390291133"},"user_tz":-330},"id":"L3HHNA_U1nd_"},"outputs":[],"source":["class FocalLossForSigmoid(nn.Module):\n","    def __init__(self, gamma=2, alpha=0.55, reduction='mean'):\n","        super(FocalLossForSigmoid, self).__init__()\n","        self.gamma = gamma\n","        assert 0 <= alpha <= 1, 'The value of alpha must in [0,1]'\n","        self.alpha = alpha\n","        self.reduction = reduction\n","        self.bce = nn.BCELoss(reduce=False)\n","\n","    def forward(self, input_, target):\n","        input_ = torch.clamp(input_, min=1e-7, max=(1 - 1e-7))\n","\n","        if self.alpha != None:\n","            loss = (self.alpha * target + (1 - target) * (1 - self.alpha)) * (\n","                torch.pow(torch.abs(target - input_), self.gamma)) * self.bce(input_, target)\n","        else:\n","            loss = torch.pow(torch.abs(target - input_), self.gamma) * self.bce(input_, target)\n","        if self.reduction == 'mean':\n","            loss = torch.mean(loss)\n","        elif self.reduction == 'sum':\n","            loss = torch.sum(loss)\n","        else:\n","            pass\n","\n","        return loss"]},{"cell_type":"markdown","metadata":{"id":"ycc0sAoN15Oa"},"source":["Train model"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1667409912123,"user":{"displayName":"Guru Aakash G","userId":"07505285016390291133"},"user_tz":-330},"id":"2VJlbOFV17i9"},"outputs":[],"source":["def train_one_model(optimizer_name, learning_rate, l2_weight_decay, gen_num, ind_num, model, batch_size, epochs, device,\n","                    train_set_name, valid_set_name,\n","                    train_set_root, valid_set_root, exp_name,\n","                    mode='train'):\n","\n","    seed = 12\n","    \n","    torch.cuda.empty_cache()\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.backends.cudnn.benchmark = True\n","\n","    #model.to(device)\n","    model.train()\n","\n","    loss_func = FocalLossForSigmoid(reduction='mean').to(device)\n","    optimizer = get_optimizer(optimizer_name, filter(lambda p: p.requires_grad, model.parameters()), learning_rate, l2_weight_decay)\n","\n","    train_set, num_return = get_datasets(train_set_name, train_set_root, True)\n","    valid_set, _ = get_datasets(valid_set_name, valid_set_root, False)\n","    train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n","    valid_loader = DataLoader(dataset=valid_set, batch_size=1, shuffle=False, num_workers=1)\n","\n","    best_f1_score = 0\n","    flag = 0\n","    count = 0\n","\n","    valid_epoch = 80\n","    metrics_name = ['flops', 'param', 'accuracy', 'recall', 'specificity', 'precision', 'f1_score', 'auroc', 'iou']\n","    metrics = {}\n","    for metric_name in metrics_name:\n","        if metric_name == 'flops' or metric_name == 'param':\n","            metrics.update({metric_name: 100})\n","        else:\n","            metrics.update({metric_name: 0})\n","\n","    try:\n","        for i in range(epochs):\n","            train_tqdm_batch = tqdm(iterable=train_loader, total=np.ceil(len(train_set) / batch_size))\n","\n","            for images, targets in train_tqdm_batch:\n","                images, targets = images.to(device), targets.to(device)\n","                optimizer.zero_grad()\n","                preds = model(images)\n","                loss = loss_func(preds, targets)\n","                loss.backward()\n","                clip_grad_norm_(model.parameters(), 0.1)\n","                optimizer.step()\n","            train_tqdm_batch.close()\n","\n","            print('gens_{} individual_{}_epoch_{} train end'.format(gen_num, ind_num, i))\n","\n","            epoch_acc = AverageMeter()\n","            epoch_recall = AverageMeter()\n","            epoch_precision = AverageMeter()\n","            epoch_specificity = AverageMeter()\n","            epoch_f1_score = AverageMeter()\n","            epoch_iou = AverageMeter()\n","            epoch_auroc = AverageMeter()\n","\n","            if (i >= valid_epoch):\n","                with torch.no_grad():\n","                    model.eval()\n","                    valid_tqdm_batch = tqdm(iterable=valid_loader, total=np.ceil(len(valid_set) / 1))\n","                    \n","                    for images, targets in valid_tqdm_batch:\n","                        images = images.to(device)\n","                        targets = targets.to(device)\n","                        preds = model(images)\n","\n","                        (acc, recall, specificity, precision,\n","                         f1_score, iou, auroc) = calculate_metrics(preds=preds, targets=targets, device=device)\n","                        epoch_acc.update(acc)\n","                        epoch_recall.update(recall)\n","                        epoch_precision.update(precision)\n","                        epoch_specificity.update(specificity)\n","                        epoch_f1_score.update(f1_score)\n","                        epoch_iou.update(iou)\n","                        epoch_auroc.update(auroc)\n","\n","                    if i == valid_epoch:\n","                        flops, param = profile(model=model, inputs=(images,), verbose=False)\n","                        flops = flops / 1e11\n","                        param = param / 1e6\n","                  \n","                    print('gens_{} individual_{}_epoch_{} validate end'.format(gen_num, ind_num, i))\n","                    print('acc:{} | recall:{} | spe:{} | pre:{} | f1_score:{} | auroc:{}'\n","                          .format(epoch_acc.val,\n","                                  epoch_recall.val,\n","                                  epoch_specificity.val,\n","                                  epoch_precision.val,\n","                                  epoch_f1_score.val,\n","                                  epoch_auroc.val))\n","                    if epoch_f1_score.val > best_f1_score:\n","                        best_f1_score = epoch_f1_score.val\n","\n","                        flag = i\n","                        count = 0\n","                        for key in list(metrics):\n","                            if key == 'flops':\n","                                metrics[key] = flops\n","                            elif key == 'param':\n","                                metrics[key] = param\n","                            elif key == 'accuracy':\n","                                metrics[key] = epoch_acc.val\n","                            elif key == 'recall':\n","                                metrics[key] = epoch_recall.val\n","                            elif key == 'specificity':\n","                                metrics[key] = epoch_specificity.val\n","                            elif key == 'precision':\n","                                metrics[key] = epoch_precision.val\n","                            elif key == 'f1_score':\n","                                metrics[key] = epoch_f1_score.val\n","                            elif key == 'auroc':\n","                                metrics[key] = epoch_auroc.val\n","                            elif key == 'iou':\n","                                metrics[key] = epoch_iou.val\n","                            else:\n","                                raise NotImplementedError\n","\n","                        import pandas as pd\n","                        from os.path import join\n","                        performance_df = pd.DataFrame(\n","                            data=[[gen_num, ind_num, epoch_acc.val, epoch_recall.val, epoch_specificity.val,\n","                                   epoch_precision.val,\n","                                   epoch_f1_score.val, epoch_iou.val, epoch_auroc.val]],\n","                            columns=['epoch', 'individual', 'acc', 'recall',\n","                                     'specificity', 'precision', 'f1_score', 'iou',\n","                                     'auroc', ]\n","\n","                        )\n","                        performance_csv_path = join(os.path.abspath(output_path), 'exps/{}/csv'.format(exp_name),\n","                                                    'gens_{} individual_{} performance.csv'.format(gen_num, ind_num))\n","                        performance_df.to_csv(performance_csv_path)\n","                    else:\n","                        if i >= valid_epoch:\n","                            count += 1\n","\n","                    end = None\n","                    if i > valid_epoch + 15 and best_f1_score < 0.50:\n","                        end = True\n","                    if (count >= 70) or end:\n","                        print('current best epoch_{} best_f1_score:'.format(flag), best_f1_score)\n","                        print('gens_{} individual_{} train early stop'.format(gen_num, ind_num))\n","                        print('=======================================================================')\n","                        valid_tqdm_batch.close()\n","                        return metrics, True\n","                    print('current best epoch_{} best_f1_score:'.format(flag), best_f1_score)\n","                    valid_tqdm_batch.close()\n","        print('current best epoch_{} best_f1_score:'.format(flag), best_f1_score)\n","        print('=======================================================================')\n","    except RuntimeError as exception:\n","        images.detach_()\n","        del images\n","        del model\n","        del targets\n","        return metrics, False\n","    return metrics, True"]},{"cell_type":"markdown","metadata":{"id":"JmoUFkZm12RS"},"source":["Train parameters"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1667409757138,"user":{"displayName":"Guru Aakash G","userId":"07505285016390291133"},"user_tz":-330},"id":"IpoYQinO15Bi"},"outputs":[],"source":["def train_population_parr(train_list, gen_num, population, batch_size, devices, epochs, exp_name, train_set_name,\n","                          valid_set_name, train_set_root, valid_set_root,\n","                          optimizer_name, learning_rate, l2_weight_decay, model_settings):\n","    seed = 12\n","    \n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    \n","    model_list = []\n","    metrics_ = []\n","    pickle_file = open(os.path.join(os.path.abspath(output_path), 'exps/{}/pickle/gens_{}individuals_code.pkl'.format(exp_name, gen_num)),'wb')\n","\n","    assert len(train_list) == len(population)\n","    for individual, inds in zip(population, train_list):\n","        list_ = {'gens_{}_individual_{}'.format(gen_num, inds): individual[:]}\n","        pickle.dump(list_, pickle_file)\n","        model_list.append(Net(gene=individual[:], model_settings=model_settings))\n","    pickle_file.close()\n","    gpu_num = len(devices)\n","    \n","    for i in np.arange(0, len(population), gpu_num):\n","        process_num = np.min((i + gpu_num, len(population))) - i\n","        pool = NoDaemonProcessPool(process_num)\n","        args = [\n","            (optimizer_name, learning_rate, l2_weight_decay, gen_num, train_list[i + j], model_list[i + j], batch_size,\n","             epochs, devices[j],\n","             train_set_name, valid_set_name,\n","             train_set_root, valid_set_root, exp_name, population, model_settings)\n","            for j in\n","            range(process_num)]\n","        metrics = pool.map(util_function, args)\n","        pool.terminate()\n","        metrics_.extend(metrics)\n","    return metrics_"]},{"cell_type":"markdown","metadata":{"id":"4z1vJ3n81wtD"},"source":["# Evolve"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1667409757139,"user":{"displayName":"Guru Aakash G","userId":"07505285016390291133"},"user_tz":-330},"id":"wV-XqK0gucj5"},"outputs":[],"source":["import matplotlib as mpl\n","mpl.use('Agg')\n","torch.multiprocessing.set_sharing_strategy('file_system')"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1667409757139,"user":{"displayName":"Guru Aakash G","userId":"07505285016390291133"},"user_tz":-330},"id":"wAsl2_MFucmq"},"outputs":[],"source":["def find_train_inds(population):\n","    i = 0\n","    train_list = []\n","    for ind in population:\n","        if ind.fitness.valid == False:\n","            train_list.append(i)\n","        i += 1\n","    return train_list\n","\n","\n","def special_initialization(population, code_list):\n","    for ind, code in zip(population, code_list):\n","        ind[:] = code\n","    return population\n","\n","\n","def save_evolution_stat_ckpt(evolution_stat_dict, exp_name, g):\n","    import pickle\n","    pickle_file1 = open(\n","        os.path.join(os.path.abspath(output_path), 'exps/{}/pickle/gens{}_evolution_stat_dict.pkl'.format(exp_name, g)),\n","        'wb')\n","    pickle.dump(evolution_stat_dict, pickle_file1)\n","    pickle_file1.close()\n","\n","\n","def reload_evolution_stat_ckpt(exp_name, g):\n","    import pickle\n","    pickle_file = open(\n","        os.path.join(os.path.abspath(output_path), 'exps/{}/pickle/gens{}_evolution_stat_dict.pkl'.format(exp_name, g)), 'rb')\n","    pkl2 = pickle.load(pickle_file)\n","    pickle_file.close()\n","    evolution_stat_dict = pkl2\n","\n","    return evolution_stat_dict\n","\n","\n","def save_population_ckpt(population, exp_name, g):\n","    import pickle\n","    pickle_file1 = open(os.path.join(os.path.abspath(output_path), 'exps/{}/pickle/gens{}_ckpt.pkl'.format(exp_name, g)),\n","                        'wb')\n","    pickle.dump(population, pickle_file1)\n","    pickle_file1.close()\n","\n","\n","def reload_population_ckpt(exp_name, g):\n","    import pickle\n","    pickle_file = open(os.path.join(os.path.abspath(output_path), 'exps/{}/pickle/gens{}_ckpt.pkl'.format(exp_name, g)), 'rb')\n","    pkl2 = pickle.load(pickle_file)\n","    pickle_file.close()\n","    population = pkl2\n","\n","    return population"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1667409757140,"user":{"displayName":"Guru Aakash G","userId":"07505285016390291133"},"user_tz":-330},"id":"wdhi_ZYNucqC"},"outputs":[],"source":["def check_dir(exp_name):\n","    exps_path = os.path.abspath(output_path)\n","    ckpt_path = os.path.join(exps_path, 'exps/{}/ckpt'.format(exp_name))\n","    runs_path = os.path.join(exps_path, 'exps/{}/runs'.format(exp_name))\n","    pickle_path = os.path.join(exps_path, 'exps/{}/pickle'.format(exp_name))\n","    csv_path = os.path.join(exps_path, 'exps/{}/csv'.format(exp_name))\n","\n","    if not os.path.exists(ckpt_path):\n","        os.makedirs(ckpt_path, exist_ok=True)\n","    if not os.path.exists(runs_path):\n","        os.makedirs(runs_path, exist_ok=True)\n","    if not os.path.exists(pickle_path):\n","        os.makedirs(pickle_path, exist_ok=True)\n","    if not os.path.exists(csv_path):\n","        os.makedirs(csv_path, exist_ok=True)\n","\n","\n","def get_gene_len(de_func_type, en_func_type, de_node_num_list, en_node_num_list, only_en=False):\n","    de_func_type_num = len(de_func_type)\n","    en_func_type_num = len(en_func_type)\n","\n","    de_node_func_gene_len = int(np.ceil(np.log2(de_func_type_num)))\n","    en_node_func_gene_len = int(np.ceil(np.log2(en_func_type_num)))\n","\n","    de_connect_gene_len_list = [None for _ in range(len(de_node_num_list))]\n","    en_connect_gene_len_list = [None for _ in range(len(en_node_num_list))]\n","\n","    for i in range(len(de_node_num_list)):\n","        de_connect_gene_len_list[i] = int(comb(de_node_num_list[i], 2))\n","    for i in range(len(en_node_num_list)):\n","        en_connect_gene_len_list[i] = int(comb(en_node_num_list[i], 2))\n","\n","    de_gene_len_list = [None for _ in range(len(de_node_num_list))]\n","    en_gene_len_list = [None for _ in range(len(en_node_num_list))]\n","\n","    for i in range(len(de_node_num_list)):\n","        de_gene_len_list[i] = de_node_func_gene_len + de_connect_gene_len_list[i]\n","    for i in range(len(en_node_num_list)):\n","        en_gene_len_list[i] = en_node_func_gene_len + en_connect_gene_len_list[i]\n","\n","    if only_en:\n","        gene_len = sum(en_gene_len_list)\n","    else:\n","        gene_len = sum(de_gene_len_list) + sum(en_gene_len_list)\n","\n","    return gene_len\n","\n","\n","def bin(n):\n","    result = ''\n","    if n:\n","        result = bin(n // 2)\n","        return result + str(n % 2)\n","    else:\n","        return result\n","\n","\n","def cxMultiPoint(ind1, ind2):\n","    size = min(len(ind1), len(ind2))\n","    cxpoints = []\n","    for _ in range(10):\n","        point = random.randint(0, size)\n","        while point in cxpoints:\n","            point = random.randint(0, size)\n","        cxpoints.append(point)\n","    cxpoints.sort()\n","    cxpoint1, cxpoint2, cxpoint3, cxpoint4, cxpoint5, cxpoint6, cxpoint7, cxpoint8, cxpoint9, cxpoint10 = cxpoints\n","    ind1[cxpoint1:cxpoint2], ind2[cxpoint1:cxpoint2] \\\n","        = ind2[cxpoint1:cxpoint2], ind1[cxpoint1:cxpoint2]\n","    ind1[cxpoint3:cxpoint4], ind2[cxpoint3:cxpoint4] \\\n","        = ind2[cxpoint3:cxpoint4], ind1[cxpoint3:cxpoint4]\n","    ind1[cxpoint5:cxpoint6], ind2[cxpoint5:cxpoint6] \\\n","        = ind2[cxpoint5:cxpoint6], ind1[cxpoint5:cxpoint6]\n","    ind1[cxpoint7:cxpoint8], ind2[cxpoint7:cxpoint8] \\\n","        = ind2[cxpoint7:cxpoint8], ind1[cxpoint7:cxpoint8]\n","    ind1[cxpoint9:cxpoint10], ind2[cxpoint9:cxpoint10] \\\n","        = ind2[cxpoint9:cxpoint10], ind1[cxpoint9:cxpoint10]\n","\n","    return ind1, ind2"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1667409757140,"user":{"displayName":"Guru Aakash G","userId":"07505285016390291133"},"user_tz":-330},"id":"JzbmvD2kvJhi","outputId":"a057c62a-3500-4fc2-8ece-d6f6195c2204"},"outputs":[{"output_type":"stream","name":"stdout","text":["[device(type='cuda', index=0), device(type='cuda', index=1), device(type='cuda', index=2), device(type='cuda', index=3)]\n"]}],"source":["gpu_num = 4\n","seed = 12\n","random.seed(seed)\n","np.random.seed(seed)\n","optimization_objects = ['f1_score']\n","optimization_weights = [1]\n","\n","channel = 20\n","en_node_num = 5\n","de_node_num = 5\n","sample_num = 3\n","exp_name = 'test'\n","crossover_rate = 0.9\n","mutation_rate = 0.7\n","flipping_rate = 0.05\n","gens = 50\n","epochs = 130\n","batch_size = 1\n","parents_num = 20\n","offsprings_num = 20\n","    \n","devices = [torch.device(type='cuda', index=i) for i in range(gpu_num)]\n","optimizer_name = 'Lookahead(Adam)'\n","learning_rate = 0.001\n","l2_weight_decay = 0\n","\n","print(devices)"]},{"cell_type":"code","source":["resume_train = False\n","train_set_name = 'DRIVE'\n","valid_set_name = 'DRIVE'\n","train_set_root = os.path.join(os.path.abspath(data_path), 'dataset', 'trainset', train_set_name)\n","valid_set_root = os.path.join(os.path.abspath(data_path), 'dataset', 'validset', valid_set_name)\n","\n","en_node_num_list = [en_node_num for _ in range(sample_num + 1)]\n","de_node_num_list = [de_node_num for _ in range((sample_num))]\n","\n","func_type = ['conv_relu_3', 'conv_mish_3', 'conv_in_relu_3',\n","             'conv_in_mish_3', 'p_conv_relu_3', 'p_conv_mish_3',\n","             'p_conv_in_relu_3', 'p_conv_in_mish_3', 'conv_relu_5',\n","             'conv_mish_5', 'conv_in_relu_5','conv_in_mish_5', 'p_conv_relu_5',\n","             'p_conv_mish_5','p_conv_in_relu_5', 'p_conv_in_mish_5']\n","\n","gene_len = get_gene_len(de_func_type=func_type, en_func_type=func_type, de_node_num_list=de_node_num_list,\n","                       en_node_num_list=en_node_num_list, only_en=False)\n","\n","model_settings = {'channel': channel, 'en_node_num_list': en_node_num_list, 'de_node_num_list': de_node_num_list,\n","                  'sample_num': sample_num, 'en_func_type': func_type, 'de_func_type': func_type}\n","\n","creator.create(\"FitnessMax\", base.Fitness, weights=optimization_weights)\n","creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n","toolbox = base.Toolbox()\n","toolbox.register(\"attr_bool\", random.randint, 0, 1)\n","toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, gene_len)\n","toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n","toolbox.register(\"mutateL\", tools.mutFlipBit, indpb=flipping_rate)\n","\n","check_dir(exp_name)\n","sum_writer = SummaryWriter(log_dir=os.path.join(os.path.abspath(output_path), 'exps/{}/runs'.format(exp_name)))\n","\n","if resume_train:\n","    g = 1\n","    exp_name_load = None\n","    population = reload_population_ckpt(exp_name_load, g=g)\n","\n","    for i in range(len(population)):\n","        if not os.path.exists(\n","                os.path.join(os.path.abspath(output_path), 'exps/{}/ckpt/individual_{}'.format(exp_name, i))):\n","            os.mkdir(os.path.join(os.path.abspath(output_path), 'exps/{}/ckpt/individual_{}'.format(exp_name, i)))\n","    if not os.path.exists(os.path.join(os.path.abspath(output_path), 'exps/{}/pickle/'.format(exp_name))):\n","        os.mkdir(os.path.join(os.path.abspath(output_path), 'exps/{}/pickle/'.format(exp_name)))\n","    offspring = None\n","\n","else:\n","    population = toolbox.population(n=parents_num)\n","    print('==========Sucessfully initialize population==========')\n","\n","    for i in range(len(population)):\n","        if not os.path.exists(os.path.join(os.path.abspath(output_path), 'exps/{}/ckpt/individual_{}'.format(exp_name, i))):\n","            os.mkdir(os.path.join(os.path.abspath(output_path), 'exps/{}/ckpt/individual_{}'.format(exp_name, i)))\n","    if not os.path.exists(os.path.join(os.path.abspath(output_path), 'exps/{}/pickle/'.format(exp_name))):\n","        os.mkdir(os.path.join(os.path.abspath(output_path), 'exps/{}/pickle/'.format(exp_name)))\n","\n","    train_list = find_train_inds(population)\n","    print('gens_{} train individuals is:'.format(0), train_list)\n","\n","    metrics = train_population_parr(train_list=train_list, gen_num=0, population=population, batch_size=batch_size,\n","                                        devices=devices, epochs=epochs, exp_name=exp_name,\n","                                        train_set_name=train_set_name,\n","                                        valid_set_name=valid_set_name, train_set_root=train_set_root,\n","                                        valid_set_root=valid_set_root, optimizer_name=optimizer_name,\n","                                        learning_rate=learning_rate,\n","                                        model_settings=model_settings, l2_weight_decay=l2_weight_decay)\n","\n","    for i in range(len(population)):\n","        fitness = []\n","        for opt_obj in optimization_objects:\n","            fitness.append(metrics[i][opt_obj])\n","        population[i].fitness.values = fitness\n","\n","    print('evaluate gens_{} successfully'.format(0))\n","    save_population_ckpt(population=population, exp_name=exp_name, g=0)\n","\n","    print('>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\n","    g = 0\n","    sum_writer.add_scalar('best_fitness', tools.selBest(population,k=1)[0].fitness.values[0], g)\n","    offspring = None"],"metadata":{"id":"aWpn-tlj9gw2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for n in range(g + 1, gens):\n","\n","    from copy import deepcopy\n","    parents = deepcopy(population)\n","    new_parents = list(map(toolbox.clone, parents))\n","    if offspring != None:\n","        del offspring\n","    offspring = toolbox.population(n=offsprings_num)\n","    if len(new_parents) >= 2:\n","        for i in range(int(np.ceil(offsprings_num // 2))):\n","            if random.random() < crossover_rate:\n","                for _ in range(10):\n","                    new_parents_list = deepcopy(tools.selTournament(new_parents, 2, tournsize=2))\n","                    gene_len = len(new_parents_list[0])\n","                    xor_result = []\n","                    for p in range(gene_len):\n","                        xor_result.append(int(new_parents_list[0][p]) ^ int(new_parents_list[1][p]))\n","                    diff = sum(xor_result) / gene_len\n","                    if diff > 0.2:\n","                        break\n","                off1, off2 = cxMultiPoint(new_parents_list[0], new_parents_list[1])\n","            else:\n","                new_parents_list = deepcopy(tools.selTournament(new_parents, 2, tournsize=2))\n","                off1, off2 = new_parents_list[0], new_parents_list[1]\n","                    \n","            offspring[i][:] = off1[:]\n","            offspring[i + 1][:] = off2[:]\n","            del off1.fitness.values\n","            del off2.fitness.values\n","            del offspring[i].fitness.values\n","            del offspring[i + 1].fitness.values\n","\n","            del new_parents_list\n","        offspring = offspring[:offsprings_num]\n","\n","        for i in range(offsprings_num):\n","            pb = mutation_rate\n","            if random.random() < pb:\n","                offspring[i][:] = toolbox.mutateL(offspring[i])[0]\n","                del offspring[i].fitness.values\n","    else:\n","        for i in range(len(offspring)):\n","            new_parents_list = deepcopy(tools.selRandom(new_parents, 1))\n","            off = toolbox.mutateL(new_parents_list[0])\n","\n","            offspring[i][:] = off[0]\n","            del offspring[i].fitness.values\n","\n","    print('gens_{} crossover and mutation successfully'.format(n))\n","    print('gens_{} mutation successfully'.format(n))\n","\n","    invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n","    train_list = find_train_inds(invalid_ind)\n","    print('gens_{} train individuals is:'.format(n), train_list)\n","    print('train individuals code are:', invalid_ind[:])\n","    metrics = train_population_parr(train_list=train_list, gen_num=n, population=invalid_ind, batch_size=batch_size,\n","                                        devices=devices, epochs=epochs, exp_name=exp_name,\n","                                        train_set_name=train_set_name,\n","                                        valid_set_name=valid_set_name, train_set_root=train_set_root,\n","                                        valid_set_root=valid_set_root, optimizer_name=optimizer_name,\n","                                        learning_rate=learning_rate,\n","                                        model_settings=model_settings, l2_weight_decay=l2_weight_decay)\n","    print('fitness of all trained model:', metrics)\n","\n","    for i in range(len(offspring)):\n","        fitness = []\n","        for opt_obj in optimization_objects:\n","            fitness.append(metrics[i][opt_obj])\n","        invalid_ind[i].fitness.values = fitness\n","\n","    cad_pop = population + offspring\n","    best5_pop = tools.selBest(cad_pop, 5)\n","    for ind in best5_pop:\n","        cad_pop.remove(ind)\n","    other_pop = tools.selTournament(cad_pop, k=parents_num - 5, tournsize=2)\n","    new_offspring = best5_pop + other_pop\n","                        \n","    sum_writer.add_scalar('best_fitness', tools.selBest(new_offspring,k=1)[0].fitness.values[0], g)\n","    population[:] = new_offspring\n","    save_population_ckpt(population=population, exp_name=exp_name, g=n)\n","\n","    print('evaluate gens_{} successfully'.format(n))\n","    print('>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>')\n","\n","best_ind = tools.selBest(population, parents_num)\n","best_inddividuals = deepcopy(best_ind[:])\n","pickle_file = open(\n","    os.path.join(os.path.abspath(output_path), 'exps/{}/pickle/gens_{} best_individuals_code.pkl'.format(exp_name, gens)),\n","    'wb')\n","pickle.dump(best_inddividuals, pickle_file)\n","pickle_file.close()"],"metadata":{"id":"KdGuKXFuP6Q2","executionInfo":{"status":"aborted","timestamp":1667409758954,"user_tz":-330,"elapsed":7,"user":{"displayName":"Guru Aakash G","userId":"07505285016390291133"}}},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.8.10 64-bit","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10"},"vscode":{"interpreter":{"hash":"f61cae94f334f6933d5b3874029c36b92a0988c5abaf22d4f8c9ffa35b94cf1d"}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}